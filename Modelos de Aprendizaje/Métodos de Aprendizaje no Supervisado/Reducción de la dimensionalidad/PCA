# Otra versión de Reducción de la dimensionalidad con PCA
# --------------------------------------------------------------
# Ejemplo de PCA en R utilizando el conjunto de datos 'iris'
# --------------------------------------------------------------

# Paso 1: Cargar el conjunto de datos
data <- read.csv ("Iris")  # Cargar datos incluidos en R
summary(data)  # Visualizar las primeras filas del conjunto de datos

# Paso 2: Preparar los datos para el PCA
#Visualización missing
sum(is.na(df))
any(is.na(df))

# Paso 3: Escalar los datos
# Es importante estandarizar los datos para que cada variable tenga media 0 y desviación estándar 1
data_scaled <- scale(data)

# Paso 4: Aplicar el PCA
pca_result <- prcomp(data_scaled, center = TRUE, scale = FALSE) #No se escalan los datos (FALSE) porque se realizo en el proceso anterior

# Paso 5: Resultados Componentes principales
pca.data <- data.frame (pca.results$x)
summary(pca_result)  # Resumen de la varianza explicada por cada componente principal

# Paso 6: Varianza explicada
# Varianza
varianzas <- pca_result$sdev^2 

#Total de la varianza de los datos
total.varianza <- sum(varianzas)

#Varianza explicada por cada componente principal
varianza.explicada <- varianzas/total.varianza

#Varianza explicada por cada componente principal
varianza.acumulada <- cumsum(varianza.explicada)

#Tomamos el número de componentes principales que explican el 90% de la varianza
n.pc <- min(which(varianza.acumulada > 0.9))

#Paso 7: Gráfico
# Etiquetas de los ejer del gráfico
x_label <- paste0 (paste('PC1', round(varianza.explicads[1] * 100, 2)), '%')
y_label <- paste0 (paste('PC2', round(varianza.explicada[2] * 100, 2)), '%')

# Graficar las observaciones proyectadas en el espacio de los primeros dos componentes
ggplot(pca_data, aes(x = PC1, y = PC2, color = Species)) +
  geom_point(size = 2) +
  labs(title = "PCA de iris: PC1 vs PC2",
       x = "Componente Principal 1 (PC1)",
       y = "Componente Principal 2 (PC2)") +
  theme_minimal()
